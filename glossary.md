# Glossary

## A

**Agent / AI Agent**: An AI system capable of autonomous action, not just generating text but executing commands, modifying files, and interacting with systems. Claude Code represented the first widely-deployed AI agent for software development.

**Alignment**: The challenge of ensuring AI systems behave according to human values and intentions. Constitutional AI represented a breakthrough in alignment by teaching models to critique and improve their own outputs.

**Anthropic**: AI safety company founded in 2021 by former OpenAI researchers, creators of Claude and pioneers of Constitutional AI and RLAIF techniques.

**API (Application Programming Interface)**: A set of protocols and tools for building software applications. In the context of AI, APIs allow developers to access AI capabilities programmatically.

**Attention Mechanism**: The core innovation of transformer architecture that allows models to focus on relevant parts of input when generating output. "Attention Is All You Need" introduced this concept in 2017.

**Augmented Intelligence**: The enhancement of human intelligence through AI collaboration, rather than replacement. The philosophy that guided Claude Code's development.

## B

**BERT (Bidirectional Encoder Representations from Transformers)**: Google's 2018 language model that processed text bidirectionally, excellent for understanding but unable to generate text like GPT models.

**Bias (in AI)**: Systematic prejudices in AI outputs resulting from biased training data or algorithms. A major ethical concern in AI-generated code that could perpetuate discrimination.

**BPE (Byte Pair Encoding)**: The tokenization algorithm that breaks text into subword units, enabling language models to handle any word by combining smaller pieces.

## C

**Chain of Thought**: A prompting technique where AI systems explain their reasoning step-by-step, improving accuracy and transparency in complex tasks.

**ChatGPT**: OpenAI's conversational AI released in November 2022 that sparked widespread public awareness of large language model capabilities.

**Claude**: Anthropic's AI assistant, first released in 2023, trained using Constitutional AI to be helpful, harmless, and honest (HHH).

**Claude Code**: The programming-focused version of Claude released in December 2024, capable of reading, writing, and executing code autonomously through terminal integration.

**Constitutional AI (CAI)**: Anthropic's training methodology where AI systems learn to follow a set of principles through self-critique and revision rather than maximizing human approval scores.

**Context Window**: The amount of text an AI model can process at once, measured in tokens. Claude 3.5's 200,000 token context window enabled understanding entire codebases.

**Copilot**: GitHub's AI pair programming tool, one of the first widespread AI coding assistants, limited to code completion rather than full autonomous development.

## D

**Democratization**: The process by which AI made software development accessible to non-programmers, enabling millions to create custom applications without learning traditional syntax.

**Distributed Accountability**: Legal principle established in 2025 recognizing that responsibility for AI-generated code is shared among developers, AI providers, and deploying organizations.

## E

**Emergence / Emergent Abilities**: Capabilities that appear suddenly in AI systems at certain scale thresholds rather than gradually improving. Larger models showed qualitatively different abilities.

**Ethical AI**: The practice of developing and deploying AI systems that respect human values, avoid bias, prevent harm, and maintain transparency.

## F

**Few-shot Learning**: The ability of large language models to perform new tasks with just a few examples, without explicit training on those tasks.

**Fine-tuning**: The process of further training a pre-trained model on specific data to specialize it for particular tasks or domains.

**Foundation Model**: A large AI model trained on broad data that can be adapted for many downstream tasks. GPT, Claude, and similar models are foundation models.

## G

**GELU (Gaussian Error Linear Unit)**: An activation function used in transformer models that helps networks learn complex patterns.

**GPT (Generative Pre-trained Transformer)**: OpenAI's series of language models that pioneered large-scale generative AI. GPT-3 in 2020 demonstrated unprecedented language capabilities.

**GPU (Graphics Processing Unit)**: Specialized hardware originally designed for graphics that became essential for training large AI models due to parallel processing capabilities.

## H

**Hallucination**: When AI models generate plausible-sounding but factually incorrect information. A major challenge in deploying AI for critical applications.

**HHH (Helpful, Harmless, Honest)**: Anthropic's framework for AI alignment, guiding Claude's development to be maximally useful while avoiding harm and deception.

**Human-in-the-Loop**: Systems where humans review or approve AI actions before execution. Common in early Claude Code deployments for safety.

## I

**IIT (Integrated Information Theory)**: A theory of consciousness that influenced how researchers thought about AI awareness and experience.

**Inference**: The process of using a trained AI model to generate outputs, as opposed to training which creates the model.

## L

**Large Language Model (LLM)**: AI models with billions of parameters trained on vast text corpora, capable of understanding and generating human-like text.

**Latency**: The delay between input and output in AI systems. Critical for real-time applications and user experience.

## M

**MCP (Model Context Protocol)**: Open standard developed by Anthropic for AI systems to interact with external tools and services, enabling Claude Code's ability to read files, execute commands, and integrate with development workflows.

**Multi-Head Attention**: Technique using multiple attention mechanisms in parallel within transformers to capture different types of relationships in data.

**Multimodal**: AI systems that can process multiple types of input (text, images, audio) rather than just text. Future direction for programming assistants.

## N

**Natural Language Programming**: Writing software by describing desired functionality in plain language rather than formal programming syntax, made possible by AI like Claude Code.

**Neural Network**: Computing systems inspired by biological neural networks, forming the basis of modern AI systems.

## P

**Parameters**: The weights and biases in a neural network that are adjusted during training. Model size is often measured in parameter count (millions or billions).

**Pair Programming**: Traditional practice of two programmers working together, revolutionized by human-AI collaboration where Claude Code served as an always-available partner.

**Positional Encoding**: Method for representing word positions in transformer models, crucial for understanding sequence order.

**Prompt Engineering**: The art and science of crafting inputs to AI systems to elicit desired outputs. Became a crucial skill for effective AI collaboration.

**Constitutional Principles**: The rules and values that guide Constitutional AI behavior, such as being helpful, harmless, and honest.

## R

**Reinforcement Learning from AI Feedback (RLAIF)**: Anthropic's technique where AI systems learn to improve by evaluating their own outputs rather than relying on human feedback.

**Reinforcement Learning from Human Feedback (RLHF)**: Training technique where models learn to maximize human preference scores. Preceded and inspired RLAIF.

**Responsible AI**: The practice of developing AI with consideration for ethical implications, fairness, transparency, and societal impact.

## S

**Scaling Laws**: Mathematical relationships discovered by researchers showing that model performance improves predictably with increases in model size, data, and compute.

**Self-Attention**: The transformer mechanism that allows each element in a sequence to attend to all other elements, enabling rich contextual understanding.

**Softmax**: Mathematical function that converts raw scores to probabilities, used in attention mechanisms and output generation.

**Supervised Fine-Tuning (SFT)**: Training phase where models learn from labeled examples of desired behavior.

**Syntax**: The formal rules governing programming language structure. AI assistance made syntax knowledge less critical than understanding problems.

## T

**Terminal**: Command-line interface where developers interact with computers through text commands. Claude Code's native environment.

**Token**: The basic unit of text processed by language models, typically subwords or word pieces rather than complete words.

**Tokenization**: The process of breaking text into tokens for processing by language models using algorithms like BPE.

**Transformer**: The neural network architecture introduced in 2017's "Attention Is All You Need" that enabled modern large language models through attention mechanisms.

**Trust Boundary**: The level of autonomy and access granted to AI systems based on demonstrated reliability and safety.

## U

**Uncertainty Quantification**: AI's ability to express confidence levels in its outputs, crucial for responsible deployment in critical applications.

## V

**Value Alignment**: Ensuring AI systems pursue goals compatible with human values. Central challenge in AI safety addressed by Constitutional AI.

**Vector Database**: Storage system for high-dimensional embeddings, enabling efficient similarity search and retrieval for AI applications.

## W

**Weight**: Numerical parameters in neural networks that are adjusted during training to capture patterns in data.

**Workflow Automation**: Using AI to automate sequences of development tasks, from code generation to testing to deployment.

## Z

**Zero-shot Learning**: AI's ability to perform tasks it was never explicitly trained on, based solely on instruction understanding. GPT-3's demonstration of this capability marked a breakthrough.

---

*This glossary covers key technical and conceptual terms from the book. As the field of AI and software development evolves rapidly, new terms emerge constantly. The definitions here reflect understanding as of July 2025.*